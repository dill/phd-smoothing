% investigating the breast cancer data
% David Lawrence Miller
% dave@ninepointeightone.net
  
\documentclass[a4paper,10pt]{article}
\setlength{\textheight}{22.5cm}
\setlength{\textwidth}{6.47in}
\setlength{\oddsidemargin}{-1mm}
\setlength{\topmargin}{0.1cm}
\setlength{\evensidemargin}{-5mm} 
 
% Load some packages
\usepackage{times, amsmath, amssymb, amsfonts, url, bm, rotating}
 
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{psfrag}
\usepackage{soul}

% top matter
\title{breast cancer data analysis}
\author{David Lawrence Miller\\Mathematical Sciences\\University of Bath\\\texttt{dave@ninepointeightone.net}}
 
% Shortcuts
% Probability
\newcommand{\prob}[1]{\mathbb{P}\left[ #1 \right]}
% fprime
\newcommand{\fprime}{f^\prime(z)}
% figure reference command
\newcommand{\fig}[1]{\emph{fig.} \ref{#1}}
% Figure reference command
\newcommand{\Fig}[1]{\emph{Fig.} \ref{#1}}
% table reference command
\newcommand{\tabref}[1]{\emph{table} \ref{#1}}
% Table reference command
\newcommand{\Tabref}[1]{\emph{Table} \ref{#1}}
% equation reference command
\newcommand{\eqn}[1]{(\ref{#1})}
% phi inverse
\newcommand{\phiinv}{\phi^{-1}}
% use other phi
\renewcommand{\phi}{\varphi}
%transpose
\newcommand{\tr}[1]{#1^{\text{T}}}
% diagonal
\newcommand{\diag}{\text{diag}}
% call \times \cross
\newcommand{\cross}{\times}
% section references
\newcommand{\secref}[1]{section \ref{#1}}
\newcommand{\Secref}[1]{Section \ref{#1}}
\newcommand{\ijth}{$ij^{\text{th}}$}
% error function
\newcommand{\erf}{\text{Erf}}
% derivative shortcuts
\newcommand{\palphaj}{\frac{\partial}{\partial \alpha_{j*}}}
\newcommand{\pbetajk}{\frac{\partial}{\partial \beta_{j*k*}}}
%nu_j shortcut + starred
\newcommand{\nuj}{\nu_j(\bm{z}^{(j)})}
\newcommand{\nujs}{\nu_{j*}(\bm{z}^{(j*)})}
% z_ik^j shortcut + with starts
\newcommand{\zijk}{z_{ik}^{(j)}}
\newcommand{\zijkss}{z_{ik*}^{(j*)}}
% z^(j) shortcut + with starts
\newcommand{\zj}{\bm{z}^{(j)}}
\newcommand{\zjs}{\bm{z}^{(j*)}}
% z^(J) shortcut + with starts
\newcommand{\zJ}{\bm{z}^{(J)}}



\begin{document}

\maketitle

\section{Setting up the data...}

Looking at the breast cancer data from Wit and McClure.

First off, load some packages....

<<>>=
library(mdspack)
library(ggplot2)
library(smida)
data(breast)
@

The data is in a list. Putting that into a \texttt{data.frame} by first taking the non-microarray data, which are:
\begin{itemize}
	\item \texttt{npi} - Nottingham prognostic index
	\item \texttt{surv.time} - surivival time
	\item \texttt{size} - size of the tumor (mm)
	\item \texttt{age.at.diag} - age at diagnosis
	\item \texttt{any.death} - whether the patient died
	\item \texttt{cancer.death} - whether that death was from cancer
	\item \texttt{cancer.grade} - cancer severity grade
\end{itemize}
Putting those in the frame \texttt{breast.dat}:
<<>>=
breast.dat<-as.data.frame(cbind(breast$npi,breast$surv.time, breast$size, breast$age.at.diag,
                                breast$any.death,breast$cancer.death,
                                breast$cancer.grade))
names(breast.dat)<-c("npi","surv.time","size","age.at.diag",
                     "any.death","cancer.death",
                     "cancer.grade")
@
And putting the microarray data in a matrix:
<<>>=
breast.array<-as.matrix(breast$dat)
@

\subsection{Response variables}

\subsubsection{NPI}

Can't look at the survival times as there are only 20 non-censored observations, instead let's try Nottingham prognostic index, NPI.
<<>>=
# save first
breast.array.full<-breast.array
breast.dat.full<-breast.dat

ind<-!is.na(breast$npi)
# array data
breast.array<-breast.array[ind,]
# other data
breast.dat<-breast.dat[ind,]
@
Excluding those observations which do not have NPI recorded we have 45 observations.

The Nottingham Prognostic Index is defined as:
\begin{equation}
\text{NPI} = 0.2(\text{size of index lesion in cm}) + \text{number of lymph nodes} + \text{tumour grade}
\end{equation}
see [[refs]] for more information. High values of NPI are bad, identifying those patients with very poor prognoses.

\subsubsection{Tumour grade}

Also look at the tumour grade. This was scored I-III. The same observations had missing values for NPI as had missing values for tumour grade.



\section{EDA}

\subsection{NPI}

Looking at the effect that each variable has on NPI, just using a simple scatter plot, see fig \ref{npi-vs-plot}. Linear regression lines are superimposed. The following code generated the figure:
<<eval=false>>=
breast.m<-melt(breast.dat,c("npi","any.death","cancer.death"))
p<-ggplot(breast.m)
p<-p+geom_point(aes(value,npi))
p<-p+facet_wrap(~variable,nrow=1,scales="free_x")
p<-p+labs(x="", y="NPI")
 p<-p+geom_smooth(aes(value,npi),method="lm")
print(p)
@
From that figure, it's easy to see the relationship between NPI and its constituent parts.
a histogram of survival time is generated with the following code (and shown in fig \ref{npi-hist}):
<<eval=false>>=
p<-ggplot(breast.m)
p<-p+geom_histogram(aes(npi),binwidth=1)
p<-p+labs(y="Frequency", x="NPI")
print(p)
@

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
breast.m<-melt(breast.dat,c("npi","any.death","cancer.death"))
p<-ggplot(breast.m)
p<-p+geom_point(aes(value,npi))
p<-p+facet_wrap(~variable,nrow=1,scales="free_x")
p<-p+labs(x="", y="NPI")
 p<-p+geom_smooth(aes(value,npi),method="lm")
print(p)
@
\end{center}
\label{npi-vs-time}
\caption{Plotting Nottingham prognostic index against the other non-microarray data. Note that both size and cancer grade have obvious linear relationships with NPI, as they are used in its calculation.}
\end{figure}

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
#p<-ggplot(breast.m)
#p<-p+geom_histogram(aes(npi),binwidth=1)
#p<-p+labs(y="Frequency", x="NPI")
#print(p)
hist(breast.m$npi,xlab="NPI",main="")
@
\end{center}
\label{npi-hist}
\caption{Histogram of Nottingham prognostic index.}
\end{figure}

\subsection{Tumour grade}

Plotting equivalent plots as for NPI...

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
breast.m<-melt(breast.dat,c("cancer.grade","any.death","cancer.death"))
p<-ggplot(breast.m)
p<-p+geom_point(aes(value,cancer.grade))
p<-p+facet_wrap(~variable,nrow=1,scales="free_x")
p<-p+labs(x="", y="Tumour grade")
 p<-p+geom_smooth(aes(value,cancer.grade),method="lm")
print(p)
@
\end{center}
\label{grade-vs-time}
\caption{WORDS}
\end{figure}

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
#p<-ggplot(breast.m)
#p<-p+geom_histogram(aes(cancer.grade),binwidth=1)
#p<-p+labs(y="Frequency", x="Tumour grade")
#print(p)
hist(breast.m$cancer.grade,xlab="Tumour grade",main="")
@
\end{center}
\label{grade-hist}
\caption{Histogram of tumour grade.}
\end{figure}



\section{Model development}

We would like to smooth over all the covariates in the model, both the age at diagnosis and the microarray data. Unfortunately this would lead to a big $p$, small $n$ problem where there are too many covariates for a smooth model to be fit.

So, to get around this problem an MDS+DS approach is used. The idea here is that distances are calculated between patients covariate values, those distances are then used to create a new data set using multidimensional scaling. This new data is in a high dimensional space (although not as high as the original data) so Duchon splines are used to smooth reliably in this new space.

Mathematically the model may be written as
\begin{equation*}
\text{response}_i = f(x_{1i}, \dots, x_{di}) + \epsilon_i, \qquad  \epsilon_i \sim D
\end{equation*}
where $D$ is some distribution and $x_{1i}, \dots, x_{di}$ is the MDS projection of datum $i$ into $d$ dimensional MDS space. $f$ is some smooth function. The response is either the tumour grade or NPI.

The dimension to use is chosen by optimising the GCV score, this is done by fitting the model in a number of different dimensions and choosing the dimensionality corresponding to the lowest GCV score. Note that there is no guarantee of the score monotonically decreasing as a function of dimension, so the score is calculated over all dimensions in a set range to ensure a minimum is found.

Before doing the analysis we also drop those columns that contain \texttt{NA} values.
<<>>=
col.ind<-colSums(is.na(breast.array))>0
breast.array<-breast.array[,!col.ind]
@

Calculating the distance matrix for the microarray data:
<<>>=
breast.dist<-dist(breast.array,diag=TRUE,upper=TRUE)
@
this can then be fed to the fitting routine.

\subsection{NPI model}

\subsubsection{Model 1 -- simple}

<<>>=
b.gcv<-gam.mds.fit(breast.dat$npi,breast.dist,NULL,45,c(2,0.85))
@
The arguments are as follows:
\begin{enumerate}
	\item \texttt{breast.dat\$npi} - the response variable
	\item \texttt{ddist} - the distance matrix
	\item \texttt{NULL} - the MDS dimension to use, \texttt{NULL} indicates selection by GCV score
	\item \texttt{45} - the basis dimension to use
	\item \texttt{c(2,0.9)} - vector of the lower bound for the dimension and upper proportion of variability explained - used for the lower and upper bounds of the MDS dimension search
\end{enumerate}
at the moment we are not including age at diagnosis in the model.

The object returned is a list, one of its elements (\texttt{gcvs}) gives the GCV score for each dimension checked. This can be used as a handy diagnostic tool to check for multimodality in the score. Such a plot is shown in figure \ref{gcvscore}.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
plot(b.gcv$scores$dim, b.gcv$scores$score,ylab="GCV score",xlab="MDS dimension",type="l")
@
\end{center}
\label{gcvscore}
\caption{GCV score as a function of MDS projection dimension for model 1.}
\end{figure}

Performing model checking, we can first look at the results of a \texttt{summary}:
<<>>=
summary(b.gcv$gam)
@
The $R^2$ is rather low and the EDF seems to indicate something strange going on. Using the ``natural'' parametrisation (see Red Book p. 208--210), we can look the EDF of each term and see what's happening.
<<>>=
X.mm<-model.matrix(b.gcv$gam)
X.qr.R<-qr.R(qr(X.mm))

S<-b.gcv$gam$smooth[[1]]$S[[1]] # pull out penalty matrix
S<-cbind(rep(0,nrow(S)),S)
S<-rbind(rep(0,ncol(S)),S)


beta.dash<-X.qr.R%*%b.gcv$gam$coefficients
new.pen<-solve(t(X.qr.R))%*%S%*%solve(X.qr.R)
new.pen<-eigen(new.pen)

# the coefficients in their "natural" parametrisation
beta.dash.dash<-t(new.pen$vectors)%*%beta.dash

# so the new parameters are in beta.dash.dash
# the EDF of the ith parameter is
lambda<-b.gcv$gam$sp
EDF<-1/(1+lambda*new.pen$values)
@
Investigating the per-parameter EDF:
<<>>=
EDF
@
and the coefficient values
<<>>=
as.vector(beta.dash.dash)
@
So there's not really any smoothing going on here, these last terms with larger coefficients and EDFs, are those terms in the nullspace of the penalty.

Things aren't looking good for this model. 

Figure \ref{gamcheck-1} we see that there are too many residuals in the lower tail of the histogram and slightly too few in the middle, this is reflected in the QQ plot. The right side of the plot doesn't suggest anything problematic, although it is rather difficult to see what is going on with such a small sample.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
gam.check(b.gcv$gam)
@
\end{center}
\label{gamcheck-1}
\caption{Results of running \texttt{gam.check} on model 1.}
\end{figure}


\subsubsection{Model 2 -- Gamma errors}

Using Gamma errors and an identity link provides a significant increase in the $R^2$.
<<>>=
b.gcv.gamma<-gam.mds.fit(breast.dat$npi,breast.dist,NULL,45,c(2,0.85),family=Gamma(link=identity))
summary(b.gcv.gamma$gam)
@
Note also the big decrease in GCV score (see figure \ref{gcvscore2} for a plot of GCV score against MDS projection dimension).

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
plot(b.gcv.gamma$scores$dim, b.gcv.gamma$scores$score,ylab="GCV score",xlab="MDS dimension",type="l")
@
\end{center}
\label{gcvscore2}
\caption{GCV score as a function of MDS projection dimension for model 2.}
\end{figure}

To check to see what information is left in the residuals, we can fit a model to them.
<<>>=
resid.data<-b.gcv.gamma$samp.mds
resid.data$response<-b.gcv.gamma$gam$residuals
b.gcv.resids<-gam(response~s(bw,bx,by,bz,bs="ds",m=c(2,1.5),k=45),data=resid.data)
summary(b.gcv.resids)
@
This looks okay, not much going on there (same when just plain TPRS is fit to the residuals).

Figure \ref{gamcheck-2} shows the results of running \texttt{gam.check}. This looks better but the QQ plot and histogram of residuals still don't look quite right.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
gam.check(b.gcv.gamma$gam)
@
\end{center}
\label{gamcheck-2}
\caption{Results of running \texttt{gam.check} on model 2.}
\end{figure}

\subsubsection{Model 3 -- quasi-likelihood}

Messing around with the quasi options gets:
<<>>=
b.gcv.quasi<-gam.mds.fit(breast.dat$npi,breast.dist,NULL,45,c(2,0.85),family=quasi(link=power(1/3),variance="mu^3"))
summary(b.gcv.quasi$gam)
@
Which gives a slightly improved $R^2$, GCV score and percent deviance explained. The histogram of residuals also looks a bit better.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
gam.check(b.gcv.quasi$gam)
@
\end{center}
\label{gamcheck-2}
\caption{Results of running \texttt{gam.check} on model 3.}
\end{figure}

Checking to see if there is any information left in the residuals, 
<<>>=
resid.data<-b.gcv.quasi$samp.mds
resid.data$response<-b.gcv.quasi$gam$residuals
b.gcv.resids<-gam(response~s(bw,bx,by,bz,bs="ds",m=c(2,1.5),k=45),data=resid.data)
summary(b.gcv.resids)
@
There doesn't seem to be anything going on there.

\subsubsection{Comparison with lasso}

Comparing the above approach with the lasso [[ref]], provided in the package \texttt{glmnet}. By default all values of the [[blah]] parameter are calculated.
<<>>=
library(glmnet)
b.lasso.full<-glmnet(breast.array,breast.dat$npi)
@
A profile of the coefficients in the lasso is shown in figure \ref{lasso-coef}. Selecting an optimal number of parameters via cross validation yields a model with 27 parameters:
<<>>=
cvmin.lasso<-cv.glmnet(breast.array,breast.dat$npi)
b.lasso<-glmnet(breast.array,breast.dat$npi,lambda=cvmin.lasso$lambda.min)
b.lasso$dim
@

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
plot(b.lasso.full)
@
\end{center}
\label{lasso-coef}
\caption{Profile of lasso coefficients.}
\end{figure}

Figure \ref{ds-lasso-err} shows the difference between truth and the fitted value per observation for both the quasi-likelihood and lasso model. Lines join the points per observation for the two models, making the plot easier to read. Only 5 lines cross the dashed line, meaning that the the estimated provided by the new model and usually the same sign as the lasso. Looking at this more quantitatively, the mean squared errors are:
<<>>=
ds.mse<-sum((breast.dat$npi-fitted(b.gcv.quasi$gam))^2)
lasso.mse<-sum((breast.dat$npi-predict(b.lasso,breast.array))^2)
ds.mse
lasso.mse
@
this confirms the idea that the MDS model is performing better than the lasso.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
ind<-1:45
quasi.err<-fitted(b.gcv.quasi$gam)-breast.dat$npi
lasso.err<-predict(b.lasso,breast.array)-breast.dat$npi

pmax<-max(quasi.err,lasso.err)
pmin<-min(quasi.err,lasso.err)

plot(seq(pmin,pmax,len=length(ind)),ind,pch=20,type="n",xlab="truth-fitted",ylab="observation")
points(quasi.err,ind,pch=19,cex=0.5,col="red")
points(lasso.err,ind,pch=19,cex=0.5,col="blue")
abline(v=0,lty=2)

for(i in 1:45){
   lines(c(quasi.err[i],lasso.err[i]),c(i,i))
}
@
\end{center}
\label{ds-lasso-err}
\caption{Difference between the truth and the fitted values. Lasso given by blue points, quasi red.}
\end{figure}


\subsection{Leave-one-out cross-validation}
\label{npi-cv}

Can use leave-one-out cross-validation to see how sensitive the results are to changes in the data.

Algorithm that was used is as follows:

\begin{enumerate}
	\item Fit the model ($f^{(-i)}$, say) to the data with the $i^\text{th}$ datum removed.
	\item Predict over all the data.
	\item Calculate and record:
		\begin{equation}
		L(f^{(-i)}) = \frac{1}{N} \sum_{i=1}^N (\text{NPI}_i -f^{(-i)}(\mathbf{x}_i))^2
		\end{equation}
\end{enumerate}

The CV score can be then calculated as:
\begin{equation}
\text{CV}(f^{(-i)}) = \frac{1}{N} \sum_{i=1}^N L(f^{(-i)})
\end{equation}

% see breast-cv-npi.R for the code for this!
For the lasso model the CV was 46.13 and for the MDS+DS model the CV score was 30.16.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Tumour grade model}

Now from the start this is going to be harder. The data is effectively multinomial, so need to use quasi-likelihood.
<<>>=
b.gcv.quasi<-gam.mds.fit(breast.dat$cancer.grade,breast.dist,NULL,45,c(2,0.85),family=quasi(link=identity,variance="constant"))
@
Using the method in the Red Book, p 231--232, we can look at the mean-variance relationship.
<<>>=
e<-b.gcv.quasi$gam$residuals
fv<-fitted(b.gcv.quasi$gam)
(lm(log(e^2)~log(fv))$coeff[2])^2
@
Trying that power and keeping the variance constant:
<<>>=
b.gcv.quasi<-gam.mds.fit(breast.dat$cancer.grade,breast.dist,NULL,45,c(2,0.85),family=quasi(link=power(0.4643001),variance="constant"))
summary(b.gcv.quasi$gam)
@
The results of running \texttt{gam.check} on this model can be found in figure \ref{grade-quasi-gamcheck} and the GCV score plot for finding the MDS projection dimension can be found in figure \ref{grade-gcv}.

\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
gam.check(b.gcv.quasi$gam)
@
\end{center}
\label{grade-quasi-gamcheck}
\caption{Results of running \texttt{gam.check} for the quasi-likelihood model for the tumour grade model.}
\end{figure}

Again, checking to see if there is any information left in the residuals:
<<>>=
resid.data<-b.gcv.quasi$samp.mds
resid.data$response<-b.gcv.quasi$gam$residuals
b.gcv.resids<-gam(response~s(bs,bt,bu,bv,bw,bx,by,bz,bs="ds",m=c(2,1.5),k=45),data=resid.data)
summary(b.gcv.resids)
@



\begin{figure}[tb]
\begin{center}
<<fig=TRUE,echo=FALSE,cache=true>>=
plot(b.gcv.quasi$scores$dim, b.gcv.quasi$scores$score,ylab="GCV score",xlab="MDS dimension",type="l")
@
\end{center}
\label{grade-gcv}
\caption{Relationship between the GCV score and the MDS projection dimension for the quasi-likelihood model for the tumour grade model.}
\end{figure}

\subsubsection{Comparison to lasso}

Again, as above, we can run a multinomial response lasso on the data
<<>>=
cvmin.lasso<-cv.glmnet(breast.array,breast.dat$cancer.grade,family="multinomial")
b.lasso<-glmnet(breast.array,breast.dat$cancer.grade,family="multinomial",lambda=cvmin.lasso$lambda.min)
@
and then calculate the MSE:
<<>>=
ds.mse<-sum((breast.dat$cancer.grade-round(fitted(b.gcv.quasi$gam),0))^2)
lasso.mse<-sum((breast.dat$cancer.grade-apply(predict(b.lasso,breast.array,type="response"),1,which.max))^2)
ds.mse
lasso.mse
@

\subsection{Leave-one-out cross-validation}

% see breast-cv-grade.R for the code!
As in section \ref{npi-cv} we can calculate the CV scores for the two models. For the lasso the CV score was 21.76 and for the MDS+DS model the score was 2.27.
 

\end{document}
